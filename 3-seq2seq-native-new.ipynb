{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "outputExpanded": false
   },
   "source": [
    "# Playing with new 2017 `tf.contrib.seq2seq`\n",
    "\n",
    "I just discovered that a [new dynamic seq2seq implementation](https://github.com/tensorflow/tensorflow/tree/24466c2e6d32621cd85f0a78d47df6eed2c5c5a6/tensorflow/contrib/seq2seq) was recently merged into master. Naturally, I wanted to try it out.\n",
    "\n",
    "`Working with commit 24466c2e6d32621cd85f0a78d47df6eed2c5c5a6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 3\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is time-major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "decoder_targets_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_targets_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, `decoder_targets` would serve as basis for both `decoder_inputs` and decoder logits. This means that their shapes should be compatible.\n",
    "\n",
    "Here we do a bit of plumbing to set this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_size, batch_size = tf.unstack(tf.shape(decoder_targets))\n",
    "\n",
    "EOS_SLICE = tf.ones([1, batch_size], dtype=tf.int32)\n",
    "PAD_SLICE = tf.zeros([1, batch_size], dtype=tf.int32)\n",
    "\n",
    "decoder_train_inputs = tf.concat_v2([EOS_SLICE, decoder_targets], axis=0)\n",
    "decoder_train_length = decoder_targets_length + 1\n",
    "\n",
    "decoder_train_targets = tf.concat_v2([decoder_targets, PAD_SLICE], axis=0)\n",
    "decoder_train_targets_seqlen, _ = tf.unstack(tf.shape(decoder_train_targets))\n",
    "decoder_train_targets_eos_mask = tf.transpose(tf.one_hot(decoder_train_length - 1, decoder_train_targets_seqlen, dtype=tf.int32), [1, 0])\n",
    "decoder_train_targets = tf.add(\n",
    "    decoder_train_targets,\n",
    "    decoder_train_targets_eos_mask,\n",
    ")  # hacky way to put EOS symbol at the end of target sequence\n",
    "\n",
    "loss_weights = tf.ones([batch_size, tf.reduce_max(decoder_train_length)], dtype=tf.float32, name=\"loss_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# oh=tf.one_hot(decoder_train_length, decoder_train_targets_seqlen, dtype=tf.int32)\n",
    "\n",
    "# sess.run([oh, decoder_train_targets_eos_mask], fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import (LSTMCell, LSTMStateTuple, EmbeddingWrapper)\n",
    "import tensorflow.contrib.seq2seq as seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.contrib.layers import embedding_lookup_unique\n",
    "\n",
    "def embedding(inputs, embedding_classes, embedding_size, scope=None):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "\n",
    "        # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "        sqrt3 = math.sqrt(3)\n",
    "        initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "        \n",
    "        embedding_values = tf.get_variable(\n",
    "            name=\"embedding\",\n",
    "            shape=[embedding_classes, embedding_size],\n",
    "            initializer=initializer,\n",
    "            dtype=tf.float32)\n",
    "        \n",
    "        return embedding_lookup_unique(embedding_values, inputs)\n",
    "\n",
    "with tf.variable_scope(\"embedding\") as scope:\n",
    "    encoder_inputs_embedded = embedding(encoder_inputs,\n",
    "                                        vocab_size,\n",
    "                                        input_embedding_size,\n",
    "                                        scope)\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "\n",
    "    decoder_train_inputs_embedded = embedding(decoder_train_inputs,\n",
    "                                              vocab_size,\n",
    "                                              input_embedding_size,\n",
    "                                              scope)\n",
    "    \n",
    "    # we'll need matrix for inference\n",
    "    embedding_matrix = tf.get_variable(\"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Encoder\") as scope:\n",
    "    encoder_cell = LSTMCell(encoder_hidden_units)\n",
    "    \n",
    "    ((encoder_fw_outputs,\n",
    "      encoder_bw_outputs),\n",
    "     (encoder_fw_state,\n",
    "      encoder_bw_state)) = (\n",
    "        tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                        cell_bw=encoder_cell,\n",
    "                                        inputs=encoder_inputs_embedded,\n",
    "                                        sequence_length=encoder_inputs_length,\n",
    "                                        dtype=tf.float32, time_major=True, scope=scope)\n",
    "        )\n",
    "\n",
    "    encoder_outputs = tf.concat_v2((encoder_fw_outputs, encoder_fw_outputs), 2)\n",
    "\n",
    "    encoder_state_c = tf.concat_v2(\n",
    "        (encoder_fw_state.c, encoder_bw_state.c), 1)\n",
    "\n",
    "    encoder_state_h = tf.concat_v2(\n",
    "        (encoder_fw_state.h, encoder_bw_state.h), 1)\n",
    "\n",
    "    encoder_state = LSTMStateTuple(\n",
    "        c=encoder_state_c,\n",
    "        h=encoder_state_h\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)\n",
    "\n",
    "with tf.variable_scope(\"Decoder\") as scope:\n",
    "    decoder_fn_train = seq2seq.simple_decoder_fn_train(encoder_state=encoder_state)\n",
    "    \n",
    "    (\n",
    "        decoder_outputs_train,\n",
    "        decoder_state_train,\n",
    "        decoder_context_state_train\n",
    "    ) = (\n",
    "        seq2seq.dynamic_rnn_decoder(\n",
    "           cell=decoder_cell,\n",
    "           decoder_fn=decoder_fn_train,\n",
    "           inputs=decoder_train_inputs_embedded,\n",
    "           sequence_length=decoder_train_length,\n",
    "           time_major=True,\n",
    "           scope=scope,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def output_fn(outputs):\n",
    "        return tf.contrib.layers.linear(outputs, vocab_size, scope=scope)\n",
    "    \n",
    "    decoder_logits_train = output_fn(decoder_outputs_train)\n",
    "    \n",
    "    decoder_prediction_train = tf.argmax(decoder_logits_train, axis=-1, name='decoder_prediction')\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    decoder_fn_inference = seq2seq.simple_decoder_fn_inference(\n",
    "        output_fn=output_fn,\n",
    "        encoder_state=encoder_state,\n",
    "        embeddings=embedding_matrix,\n",
    "        start_of_sequence_id=1,\n",
    "        end_of_sequence_id=1,\n",
    "        maximum_length=tf.reduce_max(encoder_inputs_length) + 3,\n",
    "        num_decoder_symbols=vocab_size,\n",
    "    )\n",
    "    \n",
    "    (\n",
    "        decoder_outputs_inference,\n",
    "        decoder_state_inference,\n",
    "        decoder_context_state_inference\n",
    "    ) = (\n",
    "        seq2seq.dynamic_rnn_decoder(\n",
    "           cell=decoder_cell,\n",
    "           decoder_fn=decoder_fn_inference,\n",
    "           time_major=True,\n",
    "           scope=scope,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    ## @TODO: in case of inference decoder_outputs_inference is logits, not cell_output?\n",
    "\n",
    "\n",
    "seqloss = seq2seq.sequence_loss(\n",
    "    logits=tf.transpose(decoder_logits_train, [1, 0, 2]),\n",
    "    targets=tf.transpose(decoder_train_targets, [1, 0]),\n",
    "    weights=loss_weights)\n",
    "\n",
    "loss = tf.reduce_mean(seqloss)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 9, 5]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "seq = next(batches)[0]\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    inputs_, inputs_length_ = helpers.batch(batch)\n",
    "    return {\n",
    "        encoder_inputs: inputs_,\n",
    "        encoder_inputs_length: inputs_length_,\n",
    "        decoder_targets: inputs_,\n",
    "        decoder_targets_length: inputs_length_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_inputs:0\", shape=(?, ?), dtype=int32) 8\n",
      "Tensor(\"encoder_inputs_length:0\", shape=(?,), dtype=int32) 100\n",
      "Tensor(\"decoder_targets:0\", shape=(?, ?), dtype=int32) 8\n",
      "Tensor(\"decoder_targets_length:0\", shape=(?,), dtype=int32) 100\n"
     ]
    }
   ],
   "source": [
    "for k, v in next_feed().items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Encoder/concat_v2:0' shape=(?, ?, 6) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 0.33455735445022583\n",
      "  sample 1:\n",
      "    enc input           > [6 5 6 3 2 7 0 0]\n",
      "    dec train predicted > [6 6 6 3 2 7 1 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [2 7 2 8 0 0 0 0]\n",
      "    dec train predicted > [2 7 2 8 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [3 7 8 9 7 4 4 0]\n",
      "    dec train predicted > [7 7 8 7 7 4 4 1 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.28174811601638794\n",
      "  sample 1:\n",
      "    enc input           > [7 3 6 9 6 4 6 3]\n",
      "    dec train predicted > [3 6 6 6 6 3 6 3 1]\n",
      "  sample 2:\n",
      "    enc input           > [6 9 6 0 0 0 0 0]\n",
      "    dec train predicted > [6 9 6 1 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [7 7 8 3 2 8 8 0]\n",
      "    dec train predicted > [7 7 8 3 8 8 8 1 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.27828481793403625\n",
      "  sample 1:\n",
      "    enc input           > [9 5 5 6 9 7 0 0]\n",
      "    dec train predicted > [9 5 5 9 9 7 1 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [5 2 5 9 0 0 0 0]\n",
      "    dec train predicted > [5 2 5 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [4 8 4 6 0 0 0 0]\n",
      "    dec train predicted > [4 8 4 6 1 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.25341829657554626\n",
      "  sample 1:\n",
      "    enc input           > [3 5 9 8 8 0 0 0]\n",
      "    dec train predicted > [8 8 9 8 8 1 0 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [8 5 5 4 0 0 0 0]\n",
      "    dec train predicted > [8 5 5 4 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [5 6 3 6 6 8 2 2]\n",
      "    dec train predicted > [6 6 6 6 6 5 2 2 1]\n",
      "\n",
      "batch 4000\n",
      "  minibatch loss: 0.22100839018821716\n",
      "  sample 1:\n",
      "    enc input           > [4 2 5 5 2 8 0 0]\n",
      "    dec train predicted > [4 2 5 5 2 8 1 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [6 4 9 2 6 5 0 0]\n",
      "    dec train predicted > [6 4 9 2 6 5 1 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [7 9 9 8 3 8 0 0]\n",
      "    dec train predicted > [7 9 9 8 3 8 1 0 0]\n",
      "\n",
      "batch 5000\n",
      "  minibatch loss: 0.21254658699035645\n",
      "  sample 1:\n",
      "    enc input           > [5 2 9 8 3 8 0 0]\n",
      "    dec train predicted > [5 9 9 8 3 8 1 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [4 5 8 4 6 7 0 0]\n",
      "    dec train predicted > [4 5 8 4 6 4 1 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [3 5 5 0 0 0 0 0]\n",
      "    dec train predicted > [3 5 5 1 0 0 0 0 0]\n",
      "\n",
      "batch 6000\n",
      "  minibatch loss: 0.20847775042057037\n",
      "  sample 1:\n",
      "    enc input           > [9 8 3 8 0 0 0 0]\n",
      "    dec train predicted > [9 8 3 8 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [6 4 3 9 0 0 0 0]\n",
      "    dec train predicted > [6 4 3 9 1 0 0 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [4 9 8 8 7 5 5 0]\n",
      "    dec train predicted > [4 9 8 8 2 5 5 1 0]\n",
      "\n",
      "batch 7000\n",
      "  minibatch loss: 0.16819770634174347\n",
      "  sample 1:\n",
      "    enc input           > [7 3 4 4 2 3 2 7]\n",
      "    dec train predicted > [7 4 4 4 7 7 7 7 1]\n",
      "  sample 2:\n",
      "    enc input           > [2 4 7 5 6 7 0 0]\n",
      "    dec train predicted > [2 4 7 5 6 7 1 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [5 5 6 2 4 8 0 0]\n",
      "    dec train predicted > [5 5 6 2 4 8 1 0 0]\n",
      "\n",
      "batch 8000\n",
      "  minibatch loss: 0.21074335277080536\n",
      "  sample 1:\n",
      "    enc input           > [5 8 9 7 2 0 0 0]\n",
      "    dec train predicted > [5 9 9 7 2 1 0 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [5 6 2 3 2 8 2 0]\n",
      "    dec train predicted > [5 6 2 3 2 8 2 1 0]\n",
      "  sample 3:\n",
      "    enc input           > [6 2 2 7 2 4 0 0]\n",
      "    dec train predicted > [2 2 2 7 2 4 1 0 0]\n",
      "\n",
      "batch 9000\n",
      "  minibatch loss: 0.22320136427879333\n",
      "  sample 1:\n",
      "    enc input           > [9 6 7 3 3 0 0 0]\n",
      "    dec train predicted > [9 3 7 3 3 1 0 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [8 3 5 6 3 6 3 9]\n",
      "    dec train predicted > [8 3 6 6 3 6 3 9 1]\n",
      "  sample 3:\n",
      "    enc input           > [8 8 3 7 3 6 0 0]\n",
      "    dec train predicted > [8 8 3 7 3 6 1 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_batches = 10000\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "def transpose(l):\n",
    "    return [x.T for x in l]\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            for i, (e_in, d_tg, dt_in, dt_tg, dt_pred) in enumerate(zip(\n",
    "                    fd[encoder_inputs].T, \n",
    "                    fd[decoder_targets].T,\n",
    "                    *transpose(sess.run([\n",
    "                        decoder_train_inputs,\n",
    "                        decoder_train_targets,\n",
    "                        decoder_prediction_train,\n",
    "                    ], fd))\n",
    "                )):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    enc input           > {}'.format(e_in))\n",
    "                #print('    dec target          > {}'.format(d_tg))\n",
    "                #print('    dec train input     > {}'.format(dt_in))\n",
    "                #print('    dec train target    > {}'.format(dt_tg))\n",
    "                print('    dec train predicted > {}'.format(dt_pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.2038 after 2000000 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFkCAYAAAB8RXKEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABAbEgsAABAbEgsAABAbEgsAABCb/wcYzpGFXGzgOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d3b1a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'\\\n",
    "      .format(loss_track[-1], len(loss_track)*batch_size,\n",
    "              batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
