{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "outputExpanded": false
   },
   "source": [
    "# Playing with new 2017 `tf.contrib.seq2seq`\n",
    "\n",
    "I just discovered that a [new dynamic seq2seq implementation](https://github.com/tensorflow/tensorflow/tree/24466c2e6d32621cd85f0a78d47df6eed2c5c5a6/tensorflow/contrib/seq2seq) was recently merged into master. Naturally, I wanted to try it out.\n",
    "\n",
    "`Working with commit 24466c2e6d32621cd85f0a78d47df6eed2c5c5a6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "outputExpanded": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0-alpha'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is time-major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "decoder_targets_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_targets_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, `decoder_targets` would serve as basis for both `decoder_inputs` and decoder logits. This means that their shapes should be compatible.\n",
    "\n",
    "Here we do a bit of plumbing to set this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_size, batch_size = tf.unstack(tf.shape(decoder_targets))\n",
    "\n",
    "EOS_SLICE = tf.ones([1, batch_size], dtype=tf.int32)\n",
    "PAD_SLICE = tf.zeros([1, batch_size], dtype=tf.int32)\n",
    "\n",
    "decoder_train_inputs = tf.concat_v2([EOS_SLICE, decoder_targets], axis=0)\n",
    "decoder_train_length = decoder_targets_length + 1\n",
    "\n",
    "decoder_train_targets = tf.concat_v2([decoder_targets, PAD_SLICE], axis=0)\n",
    "decoder_train_targets_seqlen, _ = tf.unstack(tf.shape(decoder_train_targets))\n",
    "decoder_train_targets_eos_mask = tf.transpose(tf.one_hot(decoder_train_length - 1, decoder_train_targets_seqlen, dtype=tf.int32), [1, 0])\n",
    "decoder_train_targets = tf.add(\n",
    "    decoder_train_targets,\n",
    "    decoder_train_targets_eos_mask,\n",
    ")  # hacky way to put EOS symbol at the end of target sequence\n",
    "\n",
    "loss_weights = tf.ones([batch_size, tf.reduce_max(decoder_train_length)], dtype=tf.float32, name=\"loss_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# oh=tf.one_hot(decoder_train_length, decoder_train_targets_seqlen, dtype=tf.int32)\n",
    "\n",
    "# sess.run([oh, decoder_train_targets_eos_mask], fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import (LSTMCell, LSTMStateTuple, EmbeddingWrapper)\n",
    "import tensorflow.contrib.seq2seq as seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.contrib.layers import embedding_lookup_unique\n",
    "\n",
    "def embedding(inputs, embedding_classes, embedding_size, scope=None):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "\n",
    "        # Uniform(-sqrt(3), sqrt(3)) has variance=1.\n",
    "        sqrt3 = math.sqrt(3)\n",
    "        initializer = tf.random_uniform_initializer(-sqrt3, sqrt3)\n",
    "        \n",
    "        embedding_values = tf.get_variable(\n",
    "            name=\"embedding\",\n",
    "            shape=[embedding_classes, embedding_size],\n",
    "            initializer=initializer,\n",
    "            dtype=tf.float32)\n",
    "        \n",
    "        return embedding_lookup_unique(embedding_values, inputs)\n",
    "\n",
    "with tf.variable_scope(\"embedding\") as scope:\n",
    "    encoder_inputs_embedded = embedding(encoder_inputs,\n",
    "                                        vocab_size,\n",
    "                                        input_embedding_size,\n",
    "                                        scope)\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "\n",
    "    decoder_train_inputs_embedded = embedding(decoder_train_inputs,\n",
    "                                              vocab_size,\n",
    "                                              input_embedding_size,\n",
    "                                              scope)\n",
    "    \n",
    "    # we'll need matrix for inference\n",
    "    embedding_matrix = tf.get_variable(\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Encoder\") as scope:\n",
    "    encoder_cell = LSTMCell(encoder_hidden_units)\n",
    "    \n",
    "    ((encoder_fw_outputs,\n",
    "      encoder_bw_outputs),\n",
    "     (encoder_fw_state,\n",
    "      encoder_bw_state)) = (\n",
    "        tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                        cell_bw=encoder_cell,\n",
    "                                        inputs=encoder_inputs_embedded,\n",
    "                                        sequence_length=encoder_inputs_length,\n",
    "                                        dtype=tf.float32, time_major=True, scope=scope)\n",
    "        )\n",
    "\n",
    "    encoder_outputs = tf.concat_v2((encoder_fw_outputs, encoder_fw_outputs), 2)\n",
    "\n",
    "    encoder_state_c = tf.concat_v2(\n",
    "        (encoder_fw_state.c, encoder_bw_state.c), 1)\n",
    "\n",
    "    encoder_state_h = tf.concat_v2(\n",
    "        (encoder_fw_state.h, encoder_bw_state.h), 1)\n",
    "\n",
    "    encoder_state = LSTMStateTuple(\n",
    "        c=encoder_state_c,\n",
    "        h=encoder_state_h\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)\n",
    "\n",
    "with tf.variable_scope(\"Decoder\") as scope:\n",
    "    decoder_fn_train = seq2seq.simple_decoder_fn_train(encoder_state=encoder_state)\n",
    "    \n",
    "    (\n",
    "        decoder_outputs_train,\n",
    "        decoder_state_train,\n",
    "        decoder_context_state_train\n",
    "    ) = (\n",
    "        seq2seq.dynamic_rnn_decoder(\n",
    "           cell=decoder_cell,\n",
    "           decoder_fn=decoder_fn_train,\n",
    "           inputs=decoder_train_inputs_embedded,\n",
    "           sequence_length=decoder_train_length,\n",
    "           time_major=True,\n",
    "           scope=scope,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def output_fn(outputs):\n",
    "        return tf.contrib.layers.linear(outputs, vocab_size, scope=scope)\n",
    "    \n",
    "    decoder_logits_train = output_fn(decoder_outputs_train)\n",
    "    \n",
    "    decoder_prediction_train = tf.argmax(decoder_logits_train, axis=-1, name='decoder_prediction')\n",
    "    \n",
    "    scope.reuse_variables()\n",
    "    \n",
    "    decoder_fn_inference = seq2seq.simple_decoder_fn_inference(\n",
    "        output_fn=output_fn,\n",
    "        encoder_state=encoder_state,\n",
    "        embeddings=embedding_matrix,\n",
    "        start_of_sequence_id=1,\n",
    "        end_of_sequence_id=1,\n",
    "        maximum_length=tf.reduce_max(encoder_inputs_length) + 3,\n",
    "        num_decoder_symbols=vocab_size,\n",
    "    )\n",
    "    \n",
    "    (\n",
    "        decoder_outputs_inference,\n",
    "        decoder_state_inference,\n",
    "        decoder_context_state_inference\n",
    "    ) = (\n",
    "        seq2seq.dynamic_rnn_decoder(\n",
    "           cell=decoder_cell,\n",
    "           decoder_fn=decoder_fn_inference,\n",
    "           time_major=True,\n",
    "           scope=scope,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    ## @TODO: in case of inference decoder_outputs_inference is logits, not cell_output?\n",
    "\n",
    "\n",
    "seqloss = seq2seq.sequence_loss(\n",
    "    logits=tf.transpose(decoder_logits_train, [1, 0, 2]),\n",
    "    targets=tf.transpose(decoder_train_targets, [1, 0]),\n",
    "    weights=loss_weights)\n",
    "\n",
    "loss = tf.reduce_mean(seqloss)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 8, 8, 7, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "seq = next(batches)[0]\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_feed():\n",
    "    batch = next(batches)\n",
    "    inputs_, inputs_length_ = helpers.batch(batch)\n",
    "    return {\n",
    "        encoder_inputs: inputs_,\n",
    "        encoder_inputs_length: inputs_length_,\n",
    "        decoder_targets: inputs_,\n",
    "        decoder_targets_length: inputs_length_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_track = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"encoder_inputs:0\", shape=(?, ?), dtype=int32) 8\n",
      "Tensor(\"encoder_inputs_length:0\", shape=(?,), dtype=int32) 100\n",
      "Tensor(\"decoder_targets:0\", shape=(?, ?), dtype=int32) 8\n",
      "Tensor(\"decoder_targets_length:0\", shape=(?,), dtype=int32) 100\n"
     ]
    }
   ],
   "source": [
    "for k, v in next_feed().items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.316000461578369\n",
      "  sample 1:\n",
      "    enc input           > [2 5 4 2 6 9 3 7]\n",
      "    dec target          > [2 5 4 2 6 9 3 7]\n",
      "    dec train input     > [1 2 5 4 2 6 9 3 7]\n",
      "    dec train target    > [2 5 4 2 6 9 3 7 1]\n",
      "    dec train predicted > [2 7 0 0 0 4 4 0 7]\n",
      "  sample 2:\n",
      "    enc input           > [2 2 5 0 0 0 0 0]\n",
      "    dec target          > [2 2 5 0 0 0 0 0]\n",
      "    dec train input     > [1 2 2 5 0 0 0 0 0]\n",
      "    dec train target    > [2 2 5 1 0 0 0 0 0]\n",
      "    dec train predicted > [5 7 4 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    enc input           > [9 2 9 8 6 0 0 0]\n",
      "    dec target          > [9 2 9 8 6 0 0 0]\n",
      "    dec train input     > [1 9 2 9 8 6 0 0 0]\n",
      "    dec train target    > [9 2 9 8 6 1 0 0 0]\n",
      "    dec train predicted > [2 8 4 8 8 3 0 0 0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.34760168194770813\n",
      "  sample 1:\n",
      "    enc input           > [5 5 5 0 0 0 0 0]\n",
      "    dec target          > [5 5 5 0 0 0 0 0]\n",
      "    dec train input     > [1 5 5 5 0 0 0 0 0]\n",
      "    dec train target    > [5 5 5 1 0 0 0 0 0]\n",
      "    dec train predicted > [5 5 5 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    enc input           > [5 7 2 4 3 5 7 0]\n",
      "    dec target          > [5 7 2 4 3 5 7 0]\n",
      "    dec train input     > [1 5 7 2 4 3 5 7 0]\n",
      "    dec train target    > [5 7 2 4 3 5 7 1 0]\n",
      "    dec train predicted > [5 7 2 4 3 5 7 1 0]\n",
      "  sample 3:\n",
      "    enc input           > [6 4 7 0 0 0 0 0]\n",
      "    dec target          > [6 4 7 0 0 0 0 0]\n",
      "    dec train input     > [1 6 4 7 0 0 0 0 0]\n",
      "    dec train target    > [6 4 7 1 0 0 0 0 0]\n",
      "    dec train predicted > [6 4 7 1 0 0 0 0 0]\n",
      "\n",
      "training interrupted\n"
     ]
    }
   ],
   "source": [
    "max_batches = 10000\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "def transpose(l):\n",
    "    return [x.T for x in l]\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            for i, (e_in, d_tg, dt_in, dt_tg, dt_pred) in enumerate(zip(\n",
    "                    fd[encoder_inputs].T, \n",
    "                    fd[decoder_targets].T,\n",
    "                    *transpose(sess.run([\n",
    "                        decoder_train_inputs,\n",
    "                        decoder_train_targets,\n",
    "                        decoder_prediction_train,\n",
    "                    ], fd))\n",
    "                )):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    enc input           > {}'.format(e_in))\n",
    "                print('    dec target          > {}'.format(d_tg))\n",
    "                print('    dec train input     > {}'.format(dt_in))\n",
    "                print('    dec train target    > {}'.format(dt_tg))\n",
    "                print('    dec train predicted > {}'.format(dt_pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_eos_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2b2721fef0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt_eos_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dt_eos_mask' is not defined"
     ]
    }
   ],
   "source": [
    "dt_eos_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.variable_scope(\"Decoder\") as scope:\n",
    "#     attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "    \n",
    "#     (attention_keys,\n",
    "#      attention_values,\n",
    "#      attention_score_fn,\n",
    "#      attention_construct_fn) = (\n",
    "#         seq2seq.prepare_attention(\n",
    "#             attention_states,\n",
    "#             attention_option=\"luong\", \n",
    "#             num_units=decoder_hidden_units)\n",
    "#     )\n",
    "    \n",
    "#     decoder_fn_train = seq2seq.attention_decoder_fn_train(\n",
    "#               encoder_state=encoder_state,\n",
    "#               attention_keys=attention_keys,\n",
    "#               attention_values=attention_values,\n",
    "#               attention_score_fn=attention_score_fn,\n",
    "#               attention_construct_fn=attention_construct_fn)\n",
    "    \n",
    "#     decoder_cell = LSTMCell(decoder_hidden_units)\n",
    "#     (decoder_outputs_train, decoder_state_train, _) = (\n",
    "#           seq2seq.dynamic_rnn_decoder(\n",
    "#               cell=decoder_cell,\n",
    "#               decoder_fn=decoder_fn_train,\n",
    "#               inputs=decoder_inputs,\n",
    "#               sequence_length=decoder_length,\n",
    "#               time_major=True,\n",
    "#               scope=scope))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
